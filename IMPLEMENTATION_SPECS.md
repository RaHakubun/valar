# å®æ–½è§„æ ¼è¯´æ˜

## ğŸ“‹ æ¨¡å‹æ¸…å•

### 1. Embeddingæ¨¡å‹ï¼ˆå¬å›ï¼‰
```
æ¨¡å‹åç§°: text-embedding-3-large
æä¾›å•†: OpenAI
ç”¨é€”: å·¥ä½œæµæ„å›¾å‘é‡åŒ–ã€éœ€æ±‚å‘é‡åŒ–
APIè°ƒç”¨: éœ€è¦API Key
ç»´åº¦: 3072
```

### 2. Rerankeræ¨¡å‹ï¼ˆé‡æ’åºï¼‰
```
æ¨¡å‹åç§°: cross-encoder/mmarco-mMiniLMv2-L12-H384-V1
æ¥æº: HuggingFace
ç”¨é€”: ç²¾ç¡®é‡æ’å€™é€‰å·¥ä½œæµ
éƒ¨ç½²æ–¹å¼: æœ¬åœ°éƒ¨ç½²
æ¨¡å‹å¤§å°: ~470MB
æ”¯æŒ: å¤šè¯­è¨€
```

ä½¿ç”¨æ–¹å¼ï¼š
```python
from sentence_transformers import CrossEncoder

model = CrossEncoder('cross-encoder/mmarco-mMiniLMv2-L12-H384-V1')
scores = model.predict([
    (atomic_need.description, candidate.intent.description)
    for candidate in candidates
])
```

### 3. LLMæ¨¡å‹ï¼ˆéœ€æ±‚åˆ†è§£ã€æ„å›¾æå–ã€ä»£ç ç”Ÿæˆï¼‰

#### ä¸»åŠ›LLMï¼ˆé€šè¿‡APIè°ƒç”¨ï¼‰
```
æ¨¡å‹: GPT-4 / GPT-4-turbo / Claude-3.5-Sonnet
ç”¨é€”:
  - éœ€æ±‚åˆ†è§£ï¼ˆUserRequest â†’ AtomicNeedåˆ—è¡¨ï¼‰
  - å·¥ä½œæµæ„å›¾è‡ªåŠ¨æ ‡æ³¨
  - ç‰‡æ®µ-éœ€æ±‚åŒ¹é…åˆ¤æ–­
  - ç¼ºå¤±ç‰‡æ®µä»£ç ç”Ÿæˆï¼ˆæœ€åæ‰‹æ®µï¼‰
APIè°ƒç”¨: ç”¨æˆ·è‡ªè¡Œé…ç½®
```

### 4. å¯é€‰ï¼šæœ¬åœ°Code LLMï¼ˆå¦‚æœéœ€è¦ç¦»çº¿ï¼‰
```
æ¨¡å‹: Qwen2.5-Coder-7B-Instruct
æ¥æº: é˜¿é‡Œäº‘/HuggingFace
ç”¨é€”: ä»£ç ç‰‡æ®µç”Ÿæˆè¾…åŠ©
éƒ¨ç½²: å¯é€‰æœ¬åœ°éƒ¨ç½²
æ¨¡å‹å¤§å°: ~15GB (FP16)
```

---

## ğŸ’» ä»£ç è¡¨ç¤ºçš„ä¼˜åŠ¿å’Œåº”ç”¨

### ä¸ºä»€ä¹ˆç”¨ä»£ç è¡¨ç¤ºï¼Ÿï¼ˆComfyBenchè®ºæ–‡è§‚ç‚¹ï¼‰

1. **LLMå‹å¥½** - å¤§å¤šæ•°LLMåœ¨ä»£ç ä¸Šè®­ç»ƒè¿‡ï¼Œç†è§£æ›´å¥½
2. **å¯è¯»æ€§å¼º** - äººç±»å’ŒLLMéƒ½æ›´å®¹æ˜“ç†è§£
3. **ç»“æ„æ¸…æ™°** - ä¾èµ–å…³ç³»ä¸€ç›®äº†ç„¶
4. **å¯ç»„åˆæ€§** - ä»£ç ç‰‡æ®µå¤©ç„¶é€‚åˆæ‹¼æ¥

### JSON vs Codeå¯¹æ¯”

#### JSONè¡¨ç¤ºï¼ˆåŸç”Ÿæ ¼å¼ï¼‰
```json
{
  "3": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "text": "a beautiful landscape",
      "clip": ["1", 0]
    }
  }
}
```
- âŒ éš¾ä»¥ç†è§£ä¾èµ–å…³ç³»
- âŒ éœ€è¦ç†è§£èŠ‚ç‚¹IDå¼•ç”¨
- âŒ LLMå®¹æ˜“äº§ç”Ÿå¹»è§‰

#### Codeè¡¨ç¤ºï¼ˆæˆ‘ä»¬ä½¿ç”¨çš„ï¼‰
```python
model, clip, vae = CheckpointLoaderSimple(ckpt_name="model.safetensors")
conditioning = CLIPTextEncode(clip=clip, text="a beautiful landscape")
latent = KSampler(model=model, positive=conditioning, ...)
image = VAEDecode(samples=latent, vae=vae)
```
- âœ… ä¾èµ–å…³ç³»æ¸…æ™°ï¼ˆå˜é‡å¼•ç”¨ï¼‰
- âœ… æ•°æ®æµä¸€ç›®äº†ç„¶
- âœ… LLMç†è§£æ›´å‡†ç¡®
- âœ… ä¾¿äºæ‹¼æ¥å’Œä¿®æ”¹

### åœ¨æˆ‘ä»¬ç³»ç»Ÿä¸­çš„åº”ç”¨

#### 1. å·¥ä½œæµå­˜å‚¨ï¼ˆé˜¶æ®µ0ï¼‰
```python
@dataclass
class WorkflowEntry:
    workflow_json: Dict        # åŸå§‹JSONï¼ˆç”¨äºæ‰§è¡Œï¼‰
    workflow_code: str         # ä»£ç è¡¨ç¤ºï¼ˆç”¨äºç†è§£å’Œæ‹¼æ¥ï¼‰
    intent: WorkflowIntent
    intent_embedding: List[float]
```

#### 2. å·¥ä½œæµæ‹†åˆ†ï¼ˆé˜¶æ®µ2.1ï¼‰
**è¾“å…¥**ï¼šå®Œæ•´å·¥ä½œæµçš„ä»£ç è¡¨ç¤º
**è¾“å‡º**ï¼šä»£ç ç‰‡æ®µåˆ—è¡¨

```python
# è¾“å…¥
code = """
model, clip, vae = CheckpointLoaderSimple(ckpt_name="model.safetensors")
conditioning_pos = CLIPTextEncode(clip=clip, text="beautiful landscape")
conditioning_neg = CLIPTextEncode(clip=clip, text="ugly, blurry")
latent_empty = EmptyLatentImage(width=512, height=512, batch_size=1)
latent = KSampler(model=model, positive=conditioning_pos, negative=conditioning_neg, latent_image=latent_empty, seed=42, steps=20)
image = VAEDecode(samples=latent, vae=vae)
_ = SaveImage(images=image, filename_prefix="output")
"""

# æ‹†åˆ†ä¸ºç‰‡æ®µ
fragments = [
    # ç‰‡æ®µ1: æ¨¡å‹åŠ è½½
    "model, clip, vae = CheckpointLoaderSimple(ckpt_name='model.safetensors')",
    
    # ç‰‡æ®µ2: æ­£é¢æç¤ºè¯ç¼–ç 
    "conditioning_pos = CLIPTextEncode(clip=clip, text='beautiful landscape')",
    
    # ç‰‡æ®µ3: è´Ÿé¢æç¤ºè¯ç¼–ç 
    "conditioning_neg = CLIPTextEncode(clip=clip, text='ugly, blurry')",
    
    # ç‰‡æ®µ4: æ½œåœ¨å›¾åƒåˆå§‹åŒ–
    "latent_empty = EmptyLatentImage(width=512, height=512, batch_size=1)",
    
    # ç‰‡æ®µ5: é‡‡æ ·ç”Ÿæˆ
    "latent = KSampler(model=model, positive=conditioning_pos, negative=conditioning_neg, latent_image=latent_empty, seed=42, steps=20)",
    
    # ç‰‡æ®µ6: è§£ç 
    "image = VAEDecode(samples=latent, vae=vae)",
    
    # ç‰‡æ®µ7: ä¿å­˜
    "_ = SaveImage(images=image, filename_prefix='output')"
]
```

#### 3. ç‰‡æ®µæ‹¼æ¥ï¼ˆé˜¶æ®µ2.3ï¼‰
ä½¿ç”¨**å‰ä½œçš„ç®—æ³•**ï¼Œä½†æ“ä½œå¯¹è±¡æ˜¯ä»£ç ï¼š

```python
# ç‰‡æ®µAï¼ˆæ¥è‡ªå·¥ä½œæµ1ï¼‰
fragment_a = """
model, clip, vae = CheckpointLoaderSimple(ckpt_name="flux.safetensors")
conditioning = CLIPTextEncode(clip=clip, text="clay style portrait")
latent_empty = EmptyLatentImage(width=1024, height=1024, batch_size=1)
latent = KSampler(model=model, positive=conditioning, latent_image=latent_empty)
image = VAEDecode(samples=latent, vae=vae)
"""

# ç‰‡æ®µBï¼ˆæ¥è‡ªå·¥ä½œæµ2ï¼‰
fragment_b = """
upscale_model = UpscaleModelLoader(model_name="4x-UltraSharp.pth")
image_upscaled = ImageUpscaleWithModel(upscale_model=upscale_model, image=input_image)
"""

# æ‹¼æ¥ï¼šè¯†åˆ«imageæ˜¯è¿æ¥ç‚¹
# 1. åˆ†æAçš„è¾“å‡ºï¼šimage (VAEDecodeçš„è¾“å‡º)
# 2. åˆ†æBçš„è¾“å…¥ï¼šimage (ImageUpscaleWithModelçš„è¾“å…¥)
# 3. é‡å‘½åBä¸­çš„input_image â†’ image
# 4. åˆå¹¶ä»£ç 

combined = """
model, clip, vae = CheckpointLoaderSimple(ckpt_name="flux.safetensors")
conditioning = CLIPTextEncode(clip=clip, text="clay style portrait")
latent_empty = EmptyLatentImage(width=1024, height=1024, batch_size=1)
latent = KSampler(model=model, positive=conditioning, latent_image=latent_empty)
image = VAEDecode(samples=latent, vae=vae)
# --- æ‹¼æ¥ç‚¹ ---
upscale_model = UpscaleModelLoader(model_name="4x-UltraSharp.pth")
image_upscaled = ImageUpscaleWithModel(upscale_model=upscale_model, image=image)
"""
```

#### 4. ä»£ç  â†” JSONè½¬æ¢ï¼ˆé˜¶æ®µ3ï¼‰
- **é˜¶æ®µ2å…¨ç¨‹ä½¿ç”¨ä»£ç è¡¨ç¤º**ï¼ˆä¾¿äºç†è§£å’Œæ‹¼æ¥ï¼‰
- **é˜¶æ®µ3è½¬æ¢ä¸ºJSON**ï¼ˆç”¨äºæ‰§è¡Œï¼‰

```python
# ä½¿ç”¨å·²æœ‰çš„åŒå‘è§£æå™¨
workflow_json = parse_code_to_prompt(combined_code)

# æ‰§è¡Œ
execute_comfyui_workflow(workflow_json)
```

---

## ğŸ¯ ç‰‡æ®µ-éœ€æ±‚åŒ¹é…çš„æç¤ºè¯è®¾è®¡

### å‚è€ƒComfyBenchçš„å¤šAgentæ¶æ„

ComfyBenchä½¿ç”¨äº†ä¸¤ä¸ªå…³é”®Agentï¼š
1. **PlanAgent** - å…¨å±€è§„åˆ’
2. **RetrievalAgent** - æ£€ç´¢å’Œå­¦ä¹ 

æˆ‘ä»¬çš„å…³é”®ç‚¹ï¼š**æ»¡è¶³æ„å›¾** > è¯­ä¹‰ç›¸ä¼¼åº¦

### æˆ‘ä»¬çš„æç¤ºè¯è®¾è®¡

#### Prompt 1: ç‰‡æ®µåŠŸèƒ½æè¿°ç”Ÿæˆ

```python
FRAGMENT_DESCRIPTION_PROMPT = """
ä½ æ˜¯ComfyUIå·¥ä½œæµä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ä»£ç ç‰‡æ®µï¼Œç”Ÿæˆç®€æ´çš„åŠŸèƒ½æè¿°ã€‚

ä»£ç ç‰‡æ®µ:
{code_fragment}

è¯·å›ç­”ï¼š
1. è¿™ä¸ªä»£ç ç‰‡æ®µçš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆä¸€å¥è¯ï¼‰
2. è¾“å…¥æ•°æ®ç±»å‹æœ‰å“ªäº›ï¼Ÿï¼ˆå¦‚IMAGE, TEXT, MODELç­‰ï¼‰
3. è¾“å‡ºæ•°æ®ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ

åªè¿”å›JSONæ ¼å¼ï¼š
{{
    "function": "ä½¿ç”¨CLIPæ¨¡å‹å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç ",
    "inputs": ["CLIP", "TEXT"],
    "outputs": ["CONDITIONING"]
}}
"""
```

#### Prompt 2: ç‰‡æ®µ-éœ€æ±‚åŒ¹é…åˆ¤æ–­ï¼ˆæ ¸å¿ƒï¼‰

```python
FRAGMENT_NEED_MATCHING_PROMPT = """
ä½ æ˜¯ComfyUIå·¥ä½œæµä¸“å®¶ã€‚è¯·åˆ¤æ–­ç»™å®šçš„ä»£ç ç‰‡æ®µæ˜¯å¦èƒ½å¤Ÿæ»¡è¶³ç”¨æˆ·çš„åŸå­éœ€æ±‚ã€‚

ç”¨æˆ·çš„åŸå­éœ€æ±‚:
æè¿°: {atomic_need.description}
ç±»åˆ«: {atomic_need.category}
æ¨¡æ€: {atomic_need.modality}
çº¦æŸæ¡ä»¶: {atomic_need.constraints}

å€™é€‰ä»£ç ç‰‡æ®µ:
{code_fragment}

ç‰‡æ®µåŠŸèƒ½æè¿°: {fragment_description}
ç‰‡æ®µè¾“å…¥: {fragment_inputs}
ç‰‡æ®µè¾“å‡º: {fragment_outputs}

è¯·å›ç­”ï¼š
1. è¿™ä¸ªä»£ç ç‰‡æ®µæ˜¯å¦èƒ½æ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼Ÿï¼ˆæ˜¯/å¦ï¼‰
2. åŒ¹é…ç½®ä¿¡åº¦ï¼Ÿï¼ˆ0-1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼‰
3. å¦‚æœä¸èƒ½å®Œå…¨æ»¡è¶³ï¼Œç¼ºå°‘ä»€ä¹ˆåŠŸèƒ½ï¼Ÿ

è¯„åˆ¤æ ‡å‡†ï¼š
- åŠŸèƒ½æ„å›¾æ˜¯å¦ä¸€è‡´ï¼ˆæœ€é‡è¦ï¼‰
- è¾“å…¥è¾“å‡ºç±»å‹æ˜¯å¦åŒ¹é…
- æ˜¯å¦æ»¡è¶³çº¦æŸæ¡ä»¶ï¼ˆå¦‚é£æ ¼ã€å°ºå¯¸ç­‰ï¼‰
- ä¸éœ€è¦å®Œå…¨ç›¸åŒï¼Œåªè¦èƒ½è¾¾åˆ°ç›®æ ‡å³å¯

è¿”å›JSONæ ¼å¼ï¼š
{{
    "matched": true/false,
    "confidence": 0.85,
    "reason": "è¯¥ç‰‡æ®µä½¿ç”¨CLIPè¿›è¡Œæ–‡æœ¬ç¼–ç ï¼Œèƒ½å¤Ÿæ»¡è¶³'æ–‡æœ¬è½¬æ¡ä»¶å‘é‡'çš„éœ€æ±‚",
    "missing_features": []
}}
"""
```

#### Prompt 3: ç‰‡æ®µç»„åˆå¯è¡Œæ€§åˆ¤æ–­

```python
FRAGMENT_COMBINATION_PROMPT = """
ä½ æ˜¯ComfyUIå·¥ä½œæµä¸“å®¶ã€‚è¯·åˆ¤æ–­ä¸¤ä¸ªä»£ç ç‰‡æ®µæ˜¯å¦å¯ä»¥å‰åæ‹¼æ¥ã€‚

ç‰‡æ®µAï¼ˆå‰ï¼‰:
{fragment_a_code}
è¾“å‡º: {fragment_a_outputs}

ç‰‡æ®µBï¼ˆåï¼‰:
{fragment_b_code}  
è¾“å…¥: {fragment_b_inputs}

è¯·å›ç­”ï¼š
1. è¿™ä¸¤ä¸ªç‰‡æ®µèƒ½å¦æ‹¼æ¥ï¼Ÿï¼ˆæ˜¯/å¦ï¼‰
2. å¦‚æœå¯ä»¥ï¼Œè¿æ¥ç‚¹åœ¨å“ªé‡Œï¼Ÿï¼ˆå˜é‡åï¼‰
3. æ˜¯å¦éœ€è¦ç±»å‹è½¬æ¢ï¼Ÿ

è¿”å›JSONæ ¼å¼ï¼š
{{
    "compatible": true/false,
    "connection_point": {{"fragment_a_var": "image", "fragment_b_var": "input_image"}},
    "type_conversion_needed": false,
    "reason": "ç‰‡æ®µAè¾“å‡ºIMAGEç±»å‹ï¼Œç‰‡æ®µBè¾“å…¥IMAGEç±»å‹ï¼Œç±»å‹åŒ¹é…"
}}
"""
```

#### Prompt 4: ç¼ºå¤±åŠŸèƒ½ä»£ç ç”Ÿæˆï¼ˆæœ€åæ‰‹æ®µï¼‰

```python
MISSING_FRAGMENT_GENERATION_PROMPT = """
ä½ æ˜¯ComfyUIå·¥ä½œæµä¸“å®¶ã€‚è¯·ç”Ÿæˆä»£ç ç‰‡æ®µæ¥å®ç°ä»¥ä¸‹åŠŸèƒ½ã€‚

éœ€æ±‚æè¿°: {atomic_need.description}
ç±»åˆ«: {atomic_need.category}
æ¨¡æ€: {atomic_need.modality}
çº¦æŸ: {atomic_need.constraints}

å¯ç”¨çš„ComfyUIèŠ‚ç‚¹ç±»å‹ï¼ˆå‚è€ƒï¼‰:
{available_node_types}

è¯·ç”ŸæˆPythoné£æ ¼çš„ComfyUIä»£ç ç‰‡æ®µã€‚

æ ¼å¼è¦æ±‚ï¼š
1. ä½¿ç”¨å‡½æ•°è°ƒç”¨é£æ ¼
2. å˜é‡å‘½åæ¸…æ™°
3. å‚æ•°ä½¿ç”¨å…·ä½“å€¼ï¼ˆå¯ä»¥æ˜¯å ä½ç¬¦ï¼‰
4. æ³¨é‡Šè¯´æ˜è¾“å…¥è¾“å‡ºç±»å‹

ç¤ºä¾‹æ ¼å¼ï¼š
```python
# è¾“å…¥: clip (CLIP), text (STRING)
conditioning = CLIPTextEncode(clip=clip, text="{{prompt}}")
# è¾“å‡º: conditioning (CONDITIONING)
```

åªè¿”å›ä»£ç ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
"""
```

---

## ğŸ”§ æ ¸å¿ƒç®—æ³•ï¼šä»£ç çº§å·¥ä½œæµæ‹†åˆ†

### ç­–ç•¥1: åŸºäºè¯­å¥çš„ç®€å•æ‹†åˆ†

```python
def split_workflow_by_statements(code: str) -> List[str]:
    """
    æŒ‰è¯­å¥æ‹†åˆ†ï¼ˆæœ€ç®€å•ï¼‰
    æ¯ä¸ªèµ‹å€¼è¯­å¥ä½œä¸ºä¸€ä¸ªç‰‡æ®µ
    """
    lines = code.strip().split('\n')
    fragments = []
    
    for line in lines:
        line = line.strip()
        if line and not line.startswith('#'):
            fragments.append(line)
    
    return fragments
```

### ç­–ç•¥2: åŸºäºåŠŸèƒ½è¯­ä¹‰çš„æ™ºèƒ½æ‹†åˆ†ï¼ˆæ¨èï¼‰

```python
def split_workflow_by_semantics(code: str) -> List[Dict]:
    """
    åŸºäºåŠŸèƒ½è¯­ä¹‰æ‹†åˆ†
    è¯†åˆ«å¸¸è§çš„åŠŸèƒ½æ¨¡å¼
    """
    
    # 1. è§£æä»£ç ä¸ºAST
    tree = ast.parse(code)
    
    # 2. è¯†åˆ«åŠŸèƒ½æ¨¡å¼
    fragments = []
    current_fragment = []
    
    for node in tree.body:
        if isinstance(node, ast.Assign):
            func_name = node.value.func.id
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯æ–°åŠŸèƒ½çš„å¼€å§‹
            if is_new_capability(func_name, current_fragment):
                # ä¿å­˜å½“å‰ç‰‡æ®µ
                if current_fragment:
                    fragments.append({
                        "code": "\n".join(current_fragment),
                        "category": infer_category(current_fragment)
                    })
                
                # å¼€å§‹æ–°ç‰‡æ®µ
                current_fragment = [ast.unparse(node)]
            else:
                # ç»§ç»­å½“å‰ç‰‡æ®µ
                current_fragment.append(ast.unparse(node))
    
    # ä¿å­˜æœ€åä¸€ä¸ªç‰‡æ®µ
    if current_fragment:
        fragments.append({
            "code": "\n".join(current_fragment),
            "category": infer_category(current_fragment)
        })
    
    return fragments

def is_new_capability(func_name: str, current_fragment: List[str]) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯æ–°åŠŸèƒ½çš„å¼€å§‹"""
    
    # åŠŸèƒ½è¾¹ç•ŒèŠ‚ç‚¹ç±»å‹
    boundary_nodes = [
        "CheckpointLoaderSimple",    # æ¨¡å‹åŠ è½½
        "EmptyLatentImage",          # æ–°å›¾åƒå¼€å§‹
        "LoadImage",                 # å›¾åƒåŠ è½½
        "UpscaleModelLoader",        # è¶…åˆ†å¼€å§‹
        "ControlNetLoader",          # ControlNetå¼€å§‹
        # ... æ›´å¤š
    ]
    
    if func_name in boundary_nodes:
        return True
    
    # å¦‚æœå½“å‰ç‰‡æ®µä¸ºç©ºï¼Œä»»ä½•èŠ‚ç‚¹éƒ½æ˜¯å¼€å§‹
    if not current_fragment:
        return True
    
    return False

def infer_category(fragment_code: List[str]) -> str:
    """æ¨æ–­ç‰‡æ®µçš„åŠŸèƒ½ç±»åˆ«"""
    
    code_text = " ".join(fragment_code)
    
    if "CheckpointLoader" in code_text:
        return "model_loading"
    elif "CLIPTextEncode" in code_text:
        return "text_encoding"
    elif "KSampler" in code_text:
        return "sampling"
    elif "VAEDecode" in code_text:
        return "decoding"
    elif "Upscale" in code_text:
        return "upscaling"
    elif "ControlNet" in code_text:
        return "controlnet"
    else:
        return "unknown"
```

### ç­–ç•¥3: æ··åˆç­–ç•¥ï¼ˆå®é™…ä½¿ç”¨ï¼‰

```python
def split_workflow_hybrid(code: str, atomic_needs: List[AtomicNeed]) -> List[Dict]:
    """
    æ··åˆç­–ç•¥ï¼š
    1. å…ˆæŒ‰è¯­ä¹‰ç²—æ‹†
    2. æ ¹æ®åŸå­éœ€æ±‚åŠ¨æ€è°ƒæ•´
    """
    
    # 1. ç²—æ‹†
    coarse_fragments = split_workflow_by_semantics(code)
    
    # 2. æ ¹æ®éœ€æ±‚è°ƒæ•´
    refined_fragments = []
    for fragment in coarse_fragments:
        # æ£€æŸ¥æ˜¯å¦èƒ½ä¸€å¯¹ä¸€åŒ¹é…æŸä¸ªéœ€æ±‚
        matched = False
        for need in atomic_needs:
            if can_satisfy_need(fragment, need):
                refined_fragments.append({
                    **fragment,
                    "matched_need": need.need_id
                })
                matched = True
                break
        
        if not matched:
            # è¿›ä¸€æ­¥ç»†æ‹†
            sub_fragments = further_split(fragment)
            refined_fragments.extend(sub_fragments)
    
    return refined_fragments
```

---

## ğŸ“Š ç®€åŒ–åçš„å®Œæ•´æ•°æ®æµ

```
ç”¨æˆ·éœ€æ±‚
    â†“
[LLM] éœ€æ±‚åˆ†è§£
    â†“
åŸå­éœ€æ±‚åˆ—è¡¨ [need_1, need_2, ...]
    â†“
[OpenAI Embedding] å‘é‡åŒ–
    â†“
[FAISSæ£€ç´¢] å¬å›å€™é€‰å·¥ä½œæµ (top-50)
    â†“
[Reranker] é‡æ’åº (top-10)
    â†“
æœ€ç»ˆå€™é€‰å·¥ä½œæµï¼ˆå®Œæ•´å·¥ä½œæµï¼Œä»£ç è¡¨ç¤ºï¼‰
    â†“
ã€è¿è¡Œæ—¶åŠ¨æ€æ‹†åˆ†ã€‘
å¯¹æ¯ä¸ªå€™é€‰å·¥ä½œæµ:
  split_workflow_by_semantics(workflow.code)
  â†’ ä»£ç ç‰‡æ®µåˆ—è¡¨
    â†“
ã€ç‰‡æ®µ-éœ€æ±‚åŒ¹é…ã€‘
ä½¿ç”¨LLMæç¤ºè¯åˆ¤æ–­ï¼š
  for each fragment:
    for each need:
      matched, confidence = llm_match(fragment, need)
    â†“
ã€ç‰‡æ®µé€‰æ‹©å’Œæ‹¼æ¥ã€‘
ä½¿ç”¨å‰ä½œç®—æ³•ï¼š
  1. è½¬æ¢ä¸ºJSON: code_to_json(fragment.code)
  2. IDåç§»: update_node_numbers()
  3. æ™ºèƒ½è¿æ¥: merge_two_flow()
  4. åˆå¹¶: merge_dicts_update()
    â†“
ã€ç¼ºå¤±ç‰‡æ®µç”Ÿæˆã€‘
å¯¹æœªåŒ¹é…çš„éœ€æ±‚:
  ä½¿ç”¨LLMç”Ÿæˆä»£ç ç‰‡æ®µ
    â†“
ã€éªŒè¯ã€‘
è¯­æ³•æ£€æŸ¥ + è¯­ä¹‰æ£€æŸ¥
    â†“
ã€åˆæˆã€‘
Code â†’ JSON + å‚æ•°è¡¥å…¨
    â†“
å¯æ‰§è¡Œå·¥ä½œæµJSON
```

---

## ğŸ¯ å…³é”®å†³ç­–æ€»ç»“

| å†³ç­–ç‚¹ | é€‰æ‹© | åŸå›  |
|--------|------|------|
| åŸå­èƒ½åŠ› | âŒ ä¸é¢„æ ‡æ³¨ | åŠ¨æ€æ‹†åˆ†æ›´çµæ´» |
| å·¥ä½œæµè¡¨ç¤º | âœ… ä»£ç ä¸ºä¸» | LLMå‹å¥½ï¼Œä¾¿äºæ‹¼æ¥ |
| Embedding | OpenAI API | æ•ˆæœå¥½ï¼Œå®˜æ–¹æ”¯æŒ |
| Reranker | mmarco-mMiniLMv2 | å¤šè¯­è¨€ï¼Œæœ¬åœ°éƒ¨ç½² |
| ç‰‡æ®µåŒ¹é… | LLMæç¤ºè¯ | æ»¡è¶³æ„å›¾ä¼˜å…ˆ |
| æ‹¼æ¥ç®—æ³• | å‰ä½œç®—æ³• | ä¸¥è°¨ï¼Œé«˜Pass Rate |

---

## ğŸ“ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **æ­å»ºåŸºç¡€æ¶æ„**
   - å®ç°ä»£ç -JSONåŒå‘è½¬æ¢å™¨çš„å®Œå–„
   - æ­å»ºå‘é‡æ£€ç´¢ç³»ç»Ÿï¼ˆFAISSï¼‰
   - é›†æˆRerankeræ¨¡å‹

2. **æ•°æ®å‡†å¤‡**
   - çˆ¬å–å·¥ä½œæµï¼ˆComfyBench + ç¤¾åŒºï¼‰
   - æ ‡æ³¨æ•´ä½“æ„å›¾ï¼ˆGPT-4è¾…åŠ©ï¼‰
   - æ„å»ºå‘é‡ç´¢å¼•

3. **æ ¸å¿ƒç®—æ³•å®ç°**
   - ä»£ç çº§å·¥ä½œæµæ‹†åˆ†ç®—æ³•
   - ç‰‡æ®µ-éœ€æ±‚åŒ¹é…ï¼ˆLLMï¼‰
   - å‰ä½œæ‹¼æ¥ç®—æ³•è¿ç§»

éœ€è¦æˆ‘å¼€å§‹å®ç°å“ªä¸ªæ¨¡å—ï¼Ÿ
