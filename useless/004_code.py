model_1, clip_1, vae_1 = checkpoint_loader_simple(ckpt_name="""dreamshaper_8.safetensors""")
image_10 = empty_latent_image(batch_size=1, height=512, width=512)
vae_2 = vae_loader(vae_name="""vae-ft-mse-840000-ema-pruned.safetensors""")
output_3 = ip_adapter_model_loader(ipadapter_file="""ip-adapter_sd15.safetensors""")
clip_4 = clip_vision_loader(clip_name="""CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors""")
image_6 = load_image(image="""woman_portrait.jpg""", upload="""image""")
conditioning_7 = clip_text_encode(clip=clip_1, text="""beautiful renaissance girl, detailed""")
conditioning_8 = clip_text_encode(clip=clip_1, text="""blurry, horror""")
output_16 = ip_adapter_advanced(clip_vision=clip_4, combine_embeds="""concat""", embeds_scaling="""V only""", end_at=1, image=image_6, ipadapter=output_3, model=model_1, start_at=0, weight=1, weight_type="""linear""")
latent_9 = k_sampler(cfg=6, denoise=1, latent_image=image_10, model=output_16, negative=conditioning_8, positive=conditioning_7, sampler_name="""ddim""", scheduler="""ddim_uniform""", seed=937143485600286, steps=25)
image_11 = vae_decode(samples=latent_9, vae=vae_2)
_ = save_image(filename_prefix="""IPAdapter""", images=image_11)
